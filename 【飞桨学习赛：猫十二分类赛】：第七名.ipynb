{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 任务描述\n",
    "利用训练的模型来预测数据所属的类别。\n",
    "\n",
    "### 数据说明\n",
    "本数据集包含12种类的猫的图片。\n",
    "\n",
    "整个数据将被分为训练集与测试集。在训练数据中，我们提供彩色的图片，如图所示。\n",
    "\n",
    "训练集：在训练集中，我们将提供高清彩色图片以及图片所属的分类。\n",
    "\n",
    "测试集：在测试数据集中，我们仅仅提供彩色图片。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "最终精度：0.97"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 安装PaddleX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddlex\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ca/03/b401c6a34685aa698e7c2fbcfad029892cbfa4b562eaaa7722037fef86ed/paddlex-2.1.0-py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (4.1.1.26)\n",
      "Collecting lap\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/bf/64/d9fb6a75b15e783952b2fec6970f033462e67db32dc43dfbb404c14e91c2/lap-0.4.0.tar.gz (1.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: flask-cors in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (3.0.8)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (5.1.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (1.6.3)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (4.36.1)\n",
      "Collecting motmetrics\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/45/41/b019fe934eb811b9aba9b335f852305b804b9c66f098d7e35c2bdb09d1c8/motmetrics-1.2.5-py3-none-any.whl (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.1/161.1 kB\u001b[0m \u001b[31m206.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: colorama in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (0.4.4)\n",
      "Collecting shapely>=1.7.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/7b/b6/580f795a835f7b93d6e5c4fb125ba4fa81eb0e8489c5ac126ac2669b9521/Shapely-1.8.5.post1-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m613.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting scikit-learn==0.23.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f4/cb/64623369f348e9bfb29ff898a57ac7c91ed4921f228e9726546614d63ccb/scikit_learn-0.23.2-cp37-cp37m-manylinux1_x86_64.whl (6.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m1.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: openpyxl in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (3.0.5)\n",
      "Collecting visualdl>=2.2.2\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/8a/e5/940426714a10c916466764eaea51ab7e10bd03896c625fcc4524a0855175/visualdl-2.4.1-py3-none-any.whl (4.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m1.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting pycocotools\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ef/c6/90220be3b39fbc4cbd203775ca47dd8dc97fae06fbd2b500637395621b7c/pycocotools-2.0.6.tar.gz (24 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting paddleslim==2.2.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/0b/dc/f46c4669d4cb35de23581a2380d55bf9d38bb6855aab1978fdb956d85da6/paddleslim-2.2.1-py3-none-any.whl (310 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m310.9/310.9 kB\u001b[0m \u001b[31m363.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: chardet in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddlex) (3.0.4)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex) (7.1.2)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex) (2.2.3)\n",
      "Requirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.2.1->paddlex) (23.2.1)\n",
      "Requirement already satisfied: numpy>=1.13.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex) (1.20.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex) (2.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from scikit-learn==0.23.2->paddlex) (0.14.1)\n",
      "Requirement already satisfied: requests in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (2.22.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.1.5)\n",
      "Requirement already satisfied: protobuf>=3.11.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (3.20.1)\n",
      "Requirement already satisfied: packaging in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (21.3)\n",
      "Requirement already satisfied: flask>=1.1.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.1.1)\n",
      "Requirement already satisfied: Flask-Babel>=1.0.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.0.0)\n",
      "Requirement already satisfied: six>=1.14.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (1.16.0)\n",
      "Requirement already satisfied: bce-python-sdk in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (0.8.53)\n",
      "Requirement already satisfied: multiprocess in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from visualdl>=2.2.2->paddlex) (0.70.11.1)\n",
      "Collecting xmltodict>=0.12.0\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/94/db/fd0326e331726f07ff7f40675cd86aa804bfd2e5016c727fa761c934990e/xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
      "Requirement already satisfied: et-xmlfile in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl->paddlex) (1.0.1)\n",
      "Requirement already satisfied: jdcal in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from openpyxl->paddlex) (1.4.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex) (3.0.0)\n",
      "Requirement already satisfied: Werkzeug>=0.15 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex) (0.16.0)\n",
      "Requirement already satisfied: click>=5.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex) (7.0)\n",
      "Requirement already satisfied: itsdangerous>=0.24 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from flask>=1.1.1->visualdl>=2.2.2->paddlex) (1.1.0)\n",
      "Requirement already satisfied: Babel>=2.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.2->paddlex) (2.8.0)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Flask-Babel>=1.0.0->visualdl>=2.2.2->paddlex) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.2.1->paddlex) (3.0.9)\n",
      "Requirement already satisfied: pycryptodome>=3.8.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.2->paddlex) (3.9.9)\n",
      "Requirement already satisfied: future>=0.6.0 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from bce-python-sdk->visualdl>=2.2.2->paddlex) (0.18.0)\n",
      "Requirement already satisfied: dill>=0.3.3 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from multiprocess->visualdl>=2.2.2->paddlex) (0.3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex) (2019.9.11)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from requests->visualdl>=2.2.2->paddlex) (1.25.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from Jinja2>=2.10.1->flask>=1.1.1->visualdl>=2.2.2->paddlex) (2.0.1)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->paddleslim==2.2.1->paddlex) (56.2.0)\n",
      "Building wheels for collected packages: lap, pycocotools\n",
      "  Building wheel for lap (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lap: filename=lap-0.4.0-cp37-cp37m-linux_x86_64.whl size=1593914 sha256=4a307a85498be85d928840cface4d77f09be5fdce14e266108286d2a9f51250f\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/5c/d0/d2/e331d17a999666b1e2eb99743cfa1742629f9d26c55c657001\n",
      "  Building wheel for pycocotools (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pycocotools: filename=pycocotools-2.0.6-cp37-cp37m-linux_x86_64.whl size=275100 sha256=00d733005dc6dd0d7ba482add07a51595de58eb21a5fd12c9a96fa9128ccfbd1\n",
      "  Stored in directory: /home/aistudio/.cache/pip/wheels/f8/94/70/046149e666bd5812b7de6b87a28dcef238f7162f4108e0b3d8\n",
      "Successfully built lap pycocotools\n",
      "Installing collected packages: lap, xmltodict, shapely, scikit-learn, pycocotools, paddleslim, motmetrics, visualdl, paddlex\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 0.24.2\n",
      "    Uninstalling scikit-learn-0.24.2:\n",
      "      Successfully uninstalled scikit-learn-0.24.2\n",
      "  Attempting uninstall: visualdl\n",
      "    Found existing installation: visualdl 2.2.0\n",
      "    Uninstalling visualdl-2.2.0:\n",
      "      Successfully uninstalled visualdl-2.2.0\n",
      "Successfully installed lap-0.4.0 motmetrics-1.2.5 paddleslim-2.2.1 paddlex-2.1.0 pycocotools-2.0.6 scikit-learn-0.23.2 shapely-1.8.5.post1 visualdl-2.4.1 xmltodict-0.13.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install paddlex\r\n",
    "# 每次启动都要重新运行"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 导入相关包（由于版本问题需要去运行下面语句，将paddlelim版本换成2.1.1）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting paddleslim==2.1.1\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/ee/e7/c6b97eb6809d14634ae5cbf287285584045d6f8949d0b436dc64cbefbf7a/paddleslim-2.1.1-py3-none-any.whl (288 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.8/288.8 kB\u001b[0m \u001b[31m461.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyzmq in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1) (23.2.1)\n",
      "Requirement already satisfied: pillow in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1) (7.1.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1) (4.36.1)\n",
      "Requirement already satisfied: opencv-python in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1) (4.1.1.26)\n",
      "Requirement already satisfied: matplotlib in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from paddleslim==2.1.1) (2.2.3)\n",
      "Requirement already satisfied: pytz in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1) (2019.3)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1) (0.10.0)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.7.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1) (1.20.3)\n",
      "Requirement already satisfied: six>=1.10 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from matplotlib->paddleslim==2.1.1) (1.1.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from kiwisolver>=1.0.1->matplotlib->paddleslim==2.1.1) (56.2.0)\n",
      "Installing collected packages: paddleslim\n",
      "  Attempting uninstall: paddleslim\n",
      "    Found existing installation: paddleslim 2.2.1\n",
      "    Uninstalling paddleslim-2.2.1:\n",
      "      Successfully uninstalled paddleslim-2.2.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "paddlex 2.1.0 requires paddleslim==2.2.1, but you have paddleslim 2.1.1 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed paddleslim-2.1.1\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip available: \u001b[0m\u001b[31;49m22.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m22.3\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install paddleslim==2.1.1\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11-04 15:44:07 MainThread @utils.py:79] WRN paddlepaddle version: 2.1.2. The dynamic graph version of PARL is under development, not fully tested and supported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  context = pyarrow.default_serialization_context()\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pyarrow/pandas_compat.py:1027: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  'floating': np.float,\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n"
     ]
    }
   ],
   "source": [
    "import warnings\r\n",
    "warnings.filterwarnings('ignore') # 忽略警告信息\r\n",
    "()\r\n",
    "import os\r\n",
    "from paddlex import transforms as T # 用于定义模型训练、验证、预测过程中，输入图像的预处理和数据增强操作\r\n",
    "                                    \r\n",
    "import paddlex as pdx\r\n",
    "import paddle\r\n",
    "from paddle.regularizer import L2Decay # L2 权重衰减正则化     \r\n",
    "\r\n",
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "import shutil # 文件文档处理库\r\n",
    "import cv2    \r\n",
    "import imghdr # 检测图片类型\r\n",
    "from PIL import Image\r\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 数据分析与处理\n",
    "## 数据导入（解压数据集：这个平台可以直接书写linux语句）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!unzip -q /home/aistudio/data/data10954/cat_12_train.zip -d data/data10954/\r\n",
    "!unzip -q /home/aistudio/data/data10954/cat_12_test.zip -d data/data10954/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00  01\t02  03\t04  05\t06  07\t08  09\t10  11\r\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>cls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8GOkTtqw7E6IHZx4olYnhzvXLCiRsUfM.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hwQDH3VBabeFXISfjlWEmYicoyr6qK1p.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RDgZKvM6sp3Tx9dlqiLNEVJjmcfQ0zI4.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArBRzHyphTxFS2be9XLaU58m34PudlEf.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kmW7GTX6uyM2A53NBZxibYRpQnIVatCH.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>G4RDpHPcFZmwK07MlLWdgTAvXrutOkQj.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>cIfTNJzpynxK4FmbsZG0Wuia8A9BD5gk.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N5XosuxBjUTGfWd8kvFS9q2YDHyK7pMr.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tvLoIG6cSO3Mbz0iugNZpFDJq54dHjxm.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>i8PW0FObIvcrETzZuRHha3DeKko79mtj.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>G0Atu3rb7qH6n4fJpRa5UPymFIzdexSQ.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>taMkvzqHyrTIjw2lcQe4Fp36xAdBG8X7.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>iLapK12FPkSltHrNExU0WmnjGv4ogIfR.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BLnEUvorlkN8TbKI6QWZ7fH3Jg4dYst2.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>zhcs9IgpHmOuFtq5wJjQ67yelC401LPi.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>ABut3Xq1nKGSVap5NCQbfFoU7gE4P0Ol.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>wdBPFf3tbl4Xmgzrh6kaTHAVL2qpM8KO.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>7Q9b3LNfzKBg0WqEu2SseFrhCZyd45AP.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>79hOMB1riogWm6wpUTfYNzaSP8Vb4Gyc.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>JlOMB5QcNgjbmrZt7xELWADsHik1uahR.jpg</td>\n",
       "      <td>00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    name cls\n",
       "0   8GOkTtqw7E6IHZx4olYnhzvXLCiRsUfM.jpg  00\n",
       "1   hwQDH3VBabeFXISfjlWEmYicoyr6qK1p.jpg  00\n",
       "2   RDgZKvM6sp3Tx9dlqiLNEVJjmcfQ0zI4.jpg  00\n",
       "3   ArBRzHyphTxFS2be9XLaU58m34PudlEf.jpg  00\n",
       "4   kmW7GTX6uyM2A53NBZxibYRpQnIVatCH.jpg  00\n",
       "5   G4RDpHPcFZmwK07MlLWdgTAvXrutOkQj.jpg  00\n",
       "6   cIfTNJzpynxK4FmbsZG0Wuia8A9BD5gk.jpg  00\n",
       "7   N5XosuxBjUTGfWd8kvFS9q2YDHyK7pMr.jpg  00\n",
       "8   tvLoIG6cSO3Mbz0iugNZpFDJq54dHjxm.jpg  00\n",
       "9   i8PW0FObIvcrETzZuRHha3DeKko79mtj.jpg  00\n",
       "10  G0Atu3rb7qH6n4fJpRa5UPymFIzdexSQ.jpg  00\n",
       "11  taMkvzqHyrTIjw2lcQe4Fp36xAdBG8X7.jpg  00\n",
       "12  iLapK12FPkSltHrNExU0WmnjGv4ogIfR.jpg  00\n",
       "13  BLnEUvorlkN8TbKI6QWZ7fH3Jg4dYst2.jpg  00\n",
       "14  zhcs9IgpHmOuFtq5wJjQ67yelC401LPi.jpg  00\n",
       "15  ABut3Xq1nKGSVap5NCQbfFoU7gE4P0Ol.jpg  00\n",
       "16  wdBPFf3tbl4Xmgzrh6kaTHAVL2qpM8KO.jpg  00\n",
       "17  7Q9b3LNfzKBg0WqEu2SseFrhCZyd45AP.jpg  00\n",
       "18  79hOMB1riogWm6wpUTfYNzaSP8Vb4Gyc.jpg  00\n",
       "19  JlOMB5QcNgjbmrZt7xELWADsHik1uahR.jpg  00"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 相关文件夹的删除与建立\r\n",
    "!rm -rf data/data10954/ImageNetDataset # 删除文件夹，防止多次运行时出错\r\n",
    "\r\n",
    "for i in range(12):\r\n",
    "    cls_path = os.path.join('data/data10954/ImageNetDataset/', '%02d' % int(i)) # 拼接路径\r\n",
    "    if not os.path.exists(cls_path):\r\n",
    "        os.makedirs(cls_path) # 创建文件夹\r\n",
    "\r\n",
    "!ls data/data10954/ImageNetDataset # 列出文件夹（linux语句）\r\n",
    "\r\n",
    "##生成文件名和类别的一一对应关系，之后将根据类别cls将图片放入目标文件夹：data/data10954/ImageNetDataset/*/*.jpg。\r\n",
    "train_df = pd.read_csv('data/data10954/train_list.txt', header=None, sep='\\t') # 读取测试集标签\r\n",
    "train_df.columns = ['name', 'cls'] # 返回列索引列表\r\n",
    "train_df['name'] = train_df['name'].apply(lambda x: str(x).strip().split('/')[-1]) # 切分文件名，舍去cat_12_train/\r\n",
    "train_df['cls'] = train_df['cls'].apply(lambda x: '%02d' % int(str(x).strip())) # 使图片标签类别变成2位数字\r\n",
    "train_df.head(20) # 观察前五行数据格式"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 图片模式检验&修复"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "图片模式主要有以下几种：  \n",
    "1、RGB 为真色彩模式， 可组合为 256 x 256 x256 种， 打印需要更改为 CMYK模式， 需要注意数值溢出的问题。  \n",
    "2、HSB 模式（本篇没有涉及），建立基于人类感觉颜色的方式，将颜色分为色相（Hue），饱和度（Saturation），明亮度（Brightness），这里不详细展开。  \n",
    "3、CMYK模式，应用在印刷领域，4个字母意思是青、洋红、黄、黑，因为不能保证纯度，所以需要黑。  \n",
    "4、位图模式，见1， 颜色由黑和白表示（True， False）。  \n",
    "5、灰度模式，只有灰度， 所有颜色转化为灰度值，见L，I，F。  \n",
    "6、双色调模式（未有涉及），节约成本将可使用双色调。  \n",
    "7、Lab模式（未涉及，ps内置），由3通道组成（亮度，a，b）组成，作为RGB到CMYK的过渡。  \n",
    "8、多通道模式，删除RGB，CMYK，Lab中某一个通道后，会转变为多通道，多通道用于处理特殊打印，它的每个通道都为256级灰度通道。  \n",
    "9、索引颜色模式，用在多媒体和网页，通过颜色表查取，没有则就近取，仅支持单通道，（8位/像素）。   \n",
    "</br>\n",
    "通过对数据集图片模式进行检验，我们发现其含有 **‘P’,’RGBA’,’RGB’** 三种不同模式的图片。  \n",
    "P（pallete）模式：调色板模式，把原来单像素占用24(32)个bit的RGB(A)真彩图片中的像素值，重映射到了8bit长，即0~255的数值范围内。而这套映射关系，就是属于这张图的所谓“调色板”(Pallete)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RGBA\n"
     ]
    }
   ],
   "source": [
    "## 图片格式应当为RGB三通道，其中一张RGBA模式图片展示如下\r\n",
    "img = Image.open('data/data10954/cat_12_train/ulFBEZNRQrxn57voHAJ4UG6Mct2sw1Cj.jpg')\r\n",
    "print(img.mode)\r\n",
    "plt.imshow(img)\r\n",
    "plt.show(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/data10954/cat_12_train/tO6cKGH8uPEayzmeZJ51Fdr2Tx3fBYSn.jpg\n",
      "P\n",
      "data/data10954/cat_12_train/ulFBEZNRQrxn57voHAJ4UG6Mct2sw1Cj.jpg\n",
      "RGBA\n",
      "data/data10954/cat_12_train/F3VnNwb2K9tgMWLodrXl1f6PIEjYqhy8.jpg\n",
      "L\n",
      "data/data10954/cat_12_train/YfsxcFB9D3LvkdQyiXlqnNZ4STwope2r.jpg\n",
      "P\n",
      "data/data10954/cat_12_train/6yYs4rvFLkQJlRxdhNfMOW52EAbgHejC.jpg\n",
      "RGBA\n",
      "data/data10954/cat_12_train/5nKsehtjrXCZqbAcSW13gxB8E6z2Luy7.jpg\n",
      "P\n",
      "data/data10954/cat_12_train/yGcJHV8Uuft6grFs7QWnK5CTAZvYzdDO.jpg\n",
      "P\n",
      "data/data10954/cat_12_train/YGyx4qCdOb7j8tzBuNfoFHLi6gU0SE3T.jpg\n",
      "RGBA\n",
      "data/data10954/cat_12_train/3yMZzWekKmuoGOF60ICQxldhBEc9Ra15.jpg\n",
      "P\n",
      "Qt29gPjYZwv3B6RJh5yiTWXrVImue1FH.jpg\n"
     ]
    }
   ],
   "source": [
    "## P、RGBA、L模式的图片转换为RGB模式\r\n",
    "for i in range(len(train_df)):\r\n",
    "    img_path = os.path.join('data/data10954/cat_12_train', train_df.at[i, 'name']) # i 元素在列中的位置 ，name 列名\r\n",
    "    if os.path.exists(img_path) and imghdr.what(img_path): # 检测路径文件是否存在及判断类别\r\n",
    "        img = Image.open(img_path) # 打开文件\r\n",
    "        if img.mode != 'RGB':\r\n",
    "            img = Image.open(img_path)\r\n",
    "            print(img_path)\r\n",
    "            print(img.mode)\r\n",
    "            img = img.convert('RGB') # 转换成rgb形式\r\n",
    "            img.save(img_path) # 保存\r\n",
    "          \r\n",
    "for img_path in os.listdir('data/data10954/cat_12_test'):\r\n",
    "    src = os.path.join('data/data10954/cat_12_test',img_path)\r\n",
    "    img = Image.open(src)\r\n",
    "    if img.mode != 'RGB':\r\n",
    "        print(img_path)\r\n",
    "        img = img.convert('RGB') \r\n",
    "        img.save(src)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4dc46e0bd0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Data Visualization\r\n",
    "## 随机查看同一类猫咪的特征\r\n",
    "plt.figure(1)\r\n",
    "img_1_1 = Image.open('data/data10954/cat_12_train/spNU7J8uk6BXiAyQErHegYMzjOaFR2qV.jpg')\r\n",
    "plt.subplot(2, 2, 1) #图一包含1行2列子图，当前画在第一行第一列图上\r\n",
    "plt.imshow(img_1_1)\r\n",
    "plt.subplot(2, 2, 2)#当前画在第一行第2列图上\r\n",
    "img_1_2 = Image.open('data/data10954/cat_12_train/7QZTYlspK2fqdJUwjC0HDmOFrM5W4PX9.jpg')\r\n",
    "plt.imshow(img_1_2)\r\n",
    "plt.subplot(2, 2, 3)\r\n",
    "img_1_3 = Image.open('data/data10954/cat_12_train/oZin4PuwTet39xWCYhUBfvlzGyISb5DV.jpg')\r\n",
    "plt.imshow(img_1_3)\r\n",
    "plt.subplot(2, 2, 4)\r\n",
    "img_1_4 = Image.open('data/data10954/cat_12_train/qbKjsR05lrFVYfLChtMGD7im36cUgAnE.jpg')\r\n",
    "plt.imshow(img_1_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f4dc4450610>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## 随机选取不同类别的猫咪进行查看\r\n",
    "plt.figure(2)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/8GOkTtqw7E6IHZx4olYnhzvXLCiRsUfM.jpg')\r\n",
    "plt.subplot(2, 6, 1)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/spNU7J8uk6BXiAyQErHegYMzjOaFR2qV.jpg')\r\n",
    "plt.subplot(2, 6, 2)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/jbIdxGyNpoql3XQZrfREMiAzh7B46WOa.jpg')\r\n",
    "plt.subplot(2, 6, 3)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/cCeBo4EJ9H1hbXsIS5G6Kxdzg27nwqfy.jpg')\r\n",
    "plt.subplot(2, 6, 4)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/yxNcRSz4TI7FpwCVJBuea6MmGitZYUkK.jpg')\r\n",
    "plt.subplot(2, 6, 5)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/NZw3P0Wfz4JDsSECG8y7HXihl2Oon6rA.jpg')\r\n",
    "plt.subplot(2, 6, 6)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/K5wdv0zEnx3cti4OagyPphCVJUIXYuSZ.jpg')\r\n",
    "plt.subplot(2, 6, 7)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/BOmo5yiKzMGV8qvleRIdLQC4bZcPxwWD.jpg')\r\n",
    "plt.subplot(2, 6, 8)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/COJUByb07wYXqcTMovWFnAgpNZk1SxrI.jpg')\r\n",
    "plt.subplot(2, 6, 9)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/dHJn0vb8XoSTM4DPG965fQ1swczARBel.jpg')\r\n",
    "plt.subplot(2, 6, 10)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/sv3RcZgEInHWtBoVKr9Q46PMUmA8Jy2h.jpg')\r\n",
    "plt.subplot(2, 6, 11)\r\n",
    "plt.imshow(img_0)\r\n",
    "img_0 = Image.open('data/data10954/cat_12_train/mrgAsyPJdDvwp1EYnUG3Hj92ehMTKNxt.jpg')\r\n",
    "plt.subplot(2, 6, 12)\r\n",
    "plt.imshow(img_0)\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.tuna.tsinghua.edu.cn/simple\n",
      "Collecting pyecharts\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/f1/f4/66f4340de85545340f54c230352419d21dfa55f01fa00aec137b283ce95c/pyecharts-1.9.1-py3-none-any.whl (135 kB)\n",
      "     l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/135.6 kB ? eta -:--:--━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━━━━━━━━━━ 41.0/135.6 kB 1.6 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━╺━━━━━━━━━━━━━━━━━━ 71.7/135.6 kB 1.2 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 112.6/135.6 kB 1.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 112.6/135.6 kB 1.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 112.6/135.6 kB 1.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 112.6/135.6 kB 1.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 112.6/135.6 kB 1.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺━━━━━━ 112.6/135.6 kB 1.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 122.9/135.6 kB 359.7 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 122.9/135.6 kB 359.7 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 122.9/135.6 kB 359.7 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 122.9/135.6 kB 359.7 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 122.9/135.6 kB 359.7 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━ 122.9/135.6 kB 359.7 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╺ 133.1/135.6 kB 230.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 135.6/135.6 kB 127.7 kB/s eta 0:00:00\n",
      "\u001b[?25hCollecting simplejson\n",
      "  Downloading https://pypi.tuna.tsinghua.edu.cn/packages/3f/0f/43cad0bb821971ef3ba4312dda4a2e611a72b7e81533470c17e1e332c170/simplejson-3.17.6-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (130 kB)\n",
      "     l     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 0.0/130.3 kB ? eta -:--:--━━━━━━━━━━━━━━━━━━╸━━━━━━━━━━━━━━━━━━━━━ 61.4/130.3 kB 2.8 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 112.6/130.3 kB 2.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 112.6/130.3 kB 2.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 112.6/130.3 kB 2.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 112.6/130.3 kB 2.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 112.6/130.3 kB 2.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 112.6/130.3 kB 2.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━━━━ 112.6/130.3 kB 2.1 MB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╸━━ 122.9/130.3 kB 389.6 kB/s eta 0:00:01━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 130.3/130.3 kB 190.5 kB/s eta 0:00:00\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pyecharts) (3.0.0)\n",
      "Requirement already satisfied: prettytable in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from pyecharts) (0.7.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0.0rc2 in /opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages (from jinja2->pyecharts) (2.0.1)\n",
      "Installing collected packages: simplejson, pyecharts\n",
      "Successfully installed pyecharts-1.9.1 simplejson-3.17.6\n",
      "\n",
      "[notice] A new release of pip available: 22.1.2 -> 22.3\n",
      "[notice] To update, run: pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "! pip install pyecharts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 样本平衡问题检验（此图像去找work文件夹中产生的labels.html打开即可看到）\n",
    "为了检验或解决本项目样本不均匀问题，我们对data/cat_12_train中各类猫的图片数量进行统计并绘制条形图，结果如下图所示。由此可以观察出，本项目不存在样本不均衡问题，可直接进行下一步操作。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/e644e5a8a89e4c06b47073caa94e4f191c64fd9891e34dc7852e6c8ba2faafdb)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 统计训练集各类猫的数目，防止样本不平衡问题。\r\n",
    "from pyecharts import options as opts\r\n",
    "from pyecharts.charts import Bar\r\n",
    "\r\n",
    "with open(\"data/data10954/train_list.txt\", \"r\") as f:\r\n",
    "    labels = f.readlines()\r\n",
    "    labels = [int(i.split()[-1]) for i in labels]\r\n",
    "\r\n",
    "counts = pd.Series(labels).value_counts().sort_index().to_list()\r\n",
    "values = np.random.rand(12) * 100\r\n",
    "names = [str(i) for i in list(range(12))]\r\n",
    "data = list(zip(values, counts, names))\r\n",
    "source = [list(i) for i in data]\r\n",
    "source.insert(0, [\"score\", \"amount\", \"product\"])\r\n",
    "\r\n",
    "\r\n",
    "c = (\r\n",
    "    Bar()\r\n",
    "    .add_dataset(\r\n",
    "        source=source\r\n",
    "    )\r\n",
    "    .add_yaxis(\r\n",
    "        series_name=\"\",\r\n",
    "        y_axis=[],\r\n",
    "        encode={\"x\": \"amount\", \"y\": \"product\"},\r\n",
    "        label_opts=opts.LabelOpts(is_show=False),\r\n",
    "    )\r\n",
    "    .set_global_opts(\r\n",
    "        title_opts=opts.TitleOpts(title=\"Dataset normal bar example\"),\r\n",
    "        xaxis_opts=opts.AxisOpts(name=\"amount\"),\r\n",
    "        yaxis_opts=opts.AxisOpts(type_=\"category\"),\r\n",
    "        visualmap_opts=opts.VisualMapOpts(\r\n",
    "            orient=\"horizontal\",\r\n",
    "            pos_left=\"center\",\r\n",
    "            min_=10,\r\n",
    "            max_=100,\r\n",
    "            range_text=[\"High Score\", \"Low Score\"],\r\n",
    "            dimension=0,\r\n",
    "            range_color=[\"#D7DA8B\", \"#E15457\"],\r\n",
    "        ),\r\n",
    "    )\r\n",
    "    .render(\"./work/labels.html\")\r\n",
    ")\r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## 从源路径 src_path 移动至目标路径 dst_path。\r\n",
    "for i in range(len(train_df)):\r\n",
    "    # 源路径\r\n",
    "    src_path = os.path.join('data/data10954/cat_12_train',train_df.at[i, 'name']) # i 元素在列中的位置 ，name 列名\r\n",
    "    # 目标路径\r\n",
    "    dst_path = os.path.join(os.path.join('data/data10954/ImageNetDataset/',train_df.at[i, 'cls']),train_df.at[i, 'name'])\r\n",
    "    try:\r\n",
    "        shutil.move(src_path, dst_path) # 移动图片到目标路径\r\n",
    "    except Exception as e: \r\n",
    "        print(e) # 抛出错误信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 数据增强\n",
    "在图像分类任务中，图像数据的增广是一种常用的正则化方法，常用于数据量不足或者模型参数较多的场景。在本章节中，我们将对除 ImageNet 分类任务标准数据增强外的8种数据增强方式进行简单的介绍和对比，用户也可以将这些增广方法应用到自己的任务中，以获得模型精度的提升。这8种数据增强方式在ImageNet上的精度指标如下所示。\n",
    "<div align=center>\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/613d6ebfebc04ae181e712ea743023a190b73c66ec334963bd716d8484349a05\" />\n",
    "</div>\n",
    "\n",
    "ImageNet 分类训练阶段的标准数据增强方式分为以下几个步骤：\n",
    "1. 图像解码：简写为 ImageDecode\n",
    "2. 随机裁剪到长宽均为 224 的图像：简写为 RandCrop\n",
    "3. 水平方向随机翻转：简写为 RandFlip\n",
    "4. 图像数据的归一化：简写为 Normalize\n",
    "5. 图像数据的重排，[224, 224, 3] 变为 [3, 224, 224]：简写为 Transpose\n",
    "6. 多幅图像数据组成 batch 数据，如 batch-size 个 [3, 224, 224] 的图像数据拼组成 [batch-size, 3, 224, 224]：简写为 Batch\n",
    "下图为三类数据增强方式的效果展示：\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/9cd7a6cf710b4ba998b201821226b8c4d7a796e0f4c5419699d69e6efb8ad1fb)\n",
    "**图像变换类**：图像变换类是在随机裁剪与翻转之间进行的操作，也可以认为是在原图上做的操作。主要方式包括AutoAugment和RandAugment，基于一定的策略，包括锐化、亮度变化、直方图均衡化等，对图像进行处理。这样网络在训练时就已经见过这些情况了，之后在实际预测时，即使遇到了光照变换、旋转这些很棘手的情况，网络也可以从容应对了。  \n",
    "**图像裁剪类**：图像裁剪类主要是在生成的在通道转换之后，在图像上设置掩码，随机遮挡，从而使得网络去学习一些非显著性的特征。否则网络一直学习很重要的显著性区域，之后在预测有遮挡的图片时，泛化能力会很差。主要方式包括：CutOut、RandErasing、HideAndSeek、GridMask。这里需要注意的是，在通道转换前后去做图像裁剪，其实是没有区别的。因为通道转换这个操作不会修改图像的像素值。  \n",
    "**图像混叠类**：组完batch之后，图像与图像、标签与标签之间进行混合，形成新的batch数据，然后送进网络进行训练。这也就是图像混叠类数据增广方式，主要的有Mixup与Cutmix两种方式。  \n",
    "由于本项目数据集中，包含2160张训练集图片，为了增强模型效果，我们采用数据增强，并通过调整方式及相关参数，使模型效果最优（相关设置请见配置文件）。  \n",
    "\n",
    "**我们以训练集中7QZTYlspK2fqdJUwjC0HDmOFrM5W4PX9.jpg为例，展示数据增强效果：**  \n",
    "**（注：由于前期使用Pytorch进行模型建立，故将相关代码放于图片下方。）**  \n",
    "\n",
    "<div align=center>\n",
    "<img src=\"https://ai-studio-static-online.cdn.bcebos.com/52322333017241dab060280e6b25cfb924a5414a7ff9454c844c8992ae669532\" />\n",
    "</div>\n",
    "\n",
    "**相关代码如下：**  \n",
    "```python\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "from timm.data.constants import IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD\n",
    "from timm import data\n",
    "\n",
    "# 数据增强策略\n",
    "trans = transforms.Compose([\n",
    "    transforms.RandomCrop((384, 384), pad_if_needed=True),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    data.AutoAugment(data.auto_augment_policy('originalr')),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(IMAGENET_DEFAULT_MEAN, IMAGENET_DEFAULT_STD),\n",
    "    transforms.RandomErasing()\n",
    "])\n",
    "\n",
    "# 加载单张图片\n",
    "image = Image.open(\"./0yTr3fswKBv4M8Fo2NcUnzibx6ClIm5e.jpg.jpg\")\n",
    "image = image.convert(\"RGB\")\n",
    "\n",
    "# 标准化的参数\n",
    "mean = np.array(IMAGENET_DEFAULT_MEAN)\n",
    "std = np.array(IMAGENET_DEFAULT_STD)\n",
    "\n",
    "# 进行绘图\n",
    "plt.figure(figsize=(12, 12))\n",
    "for i in range(25):\n",
    "    plt.subplot(5, 5, i + 1)\n",
    "    # 对图片进行增强\n",
    "    trans_image = trans(image)\n",
    "    # 提取增强后的图片，转换为numpy.ndarray格式\n",
    "    trans_image = trans_image.numpy().transpose([1, 2, 0])\n",
    "    # 反标准化\n",
    "    trans_image = std * trans_image + mean\n",
    "    trans_image = np.clip(trans_image, 0, 1)\n",
    "    # 展示图片\n",
    "    plt.imshow(trans_image)\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.savefig('./src/0yTr3fswKBv4M8Fo2NcUnzibx6ClIm5e.jpg_2.jpg', dpi=100)\n",
    "plt.show()\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 模型构建"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型概述（ResNet）\n",
    "**ResNet的诞生**\n",
    "深度网络的退化问题（Degradation problem）：网络深度增加时，网络准确度出现饱和，甚至出现下降。深度网络的退化问题至少说明深度网络不容易训练。但是我们考虑这样一个事实：现在你有一个浅层网络，你想通过向上堆积新层来建立深层网络，一个极端情况是这些增加的层什么也不学习，仅仅复制浅层网络的特征，即这样新层是恒等映射（Identity mapping）。在这种情况下，深层网络应该至少和浅层网络性能一样，也不应该出现退化现象。为了解决这个问题，ResNet的作者何凯明提出了残差学习来解决退化问题。  \n",
    "对于一个堆积层结构（几层堆积而成）当输入为 时其学习到的特征记为 ，现在我们希望其可以学习到残差   ，这样其实原始的学习特征是   。之所以这样是因为残差学习相比原始特征直接学习更容易。当残差为0时，此时堆积层仅仅做了恒等映射，至少网络性能不会下降，实际上残差不会为0，这也会使得堆积层在输入特征基础上学习到新的特征，从而拥有更好的性能。残差学习的结构如下图所示。这有点类似与电路中的“短路”，所以是一种短路连接（shortcut connection）。  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/0ecd6553881040fb9f63991cecc8ff8866f08a0ec5534529869ca1898ed9125b)  \n",
    "ResNet网络是参考了VGG19网络，在其基础上进行了修改，并通过短路机制加入了残差单元，如图5所示。变化主要体现在ResNet直接使用stride=2的卷积做下采样，并且用global average pool层替换了全连接层。ResNet的一个重要设计原则是：当feature map大小降低一半时，feature map的数量增加一倍，这保持了网络层的复杂度。从图5中可以看到，ResNet相比普通网络每两层间增加了短路机制，这就形成了残差学习，其中虚线表示feature map数量发生了改变。图5展示的34-layer的ResNet，还可以构建更深的网络如表1所示。从表中可以看到，对于18-layer和34-layer的ResNet，其进行的两层间的残差学习，当网络更深时，其进行的是三层间的残差学习，三层卷积核分别是1x1，3x3和1x1，一个值得注意的是隐含层的feature map数量是比较小的，并且是输出feature map数量的1/4。  \n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/487e996065914e62a8c410b1163981d19bd4d07932854503a7db243cdeeedc3d)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# PaddleClas训练模型\n",
    "PaddleClas支持通过修改配置文件(.yaml)的方式，灵活便捷的配置模型训练参数。相关配置文件已放于相应文件夹下。本文重点介绍全局配置(Global)、优化器(Optimizer)相关参数。  \n",
    "## 全局配置相关参数\n",
    "\n",
    "| 参数名字 | 参数名字\t | 默认值 | 可选值 |\n",
    "| :------: | :-------: | :-------: | :-------: |\n",
    "| checkpoints | 断点模型路径，用于恢复训练 | null | str |\n",
    "| pretrained_model | 预训练模型路径 | null | str|\n",
    "| output_dir | output_dir |\t\"./output/\" | str |\n",
    "| save_interval | save_interval | 1 | int |\n",
    "| eval_during_train | 是否在训练时进行评估 | True | bool |\n",
    "| eval_interval\t| 每隔多少个epoch进行模型评估 | 1 | int |\n",
    "| epochs | 训练总epoch数 |  | int |\n",
    "| print_batch_step | print_batch_step| 10 |\tint |\n",
    "| use_visualdl | 是否是用visualdl可视化训练过程 | False | bool |\n",
    "| image_shape | 图片大小 | [3，224，224] | list, shape: (3,) |\n",
    "| save_inference_dir | save_inference_dir | \"./inference\" | str |\n",
    "| eval_mode | eval的模式 |\t\"classification\" | \"retrieval\" |\n",
    "| to_static | 是否改为静态图模式 | False | True |\n",
    "| ues_dali | 是否使用dali库进行图像预处理 | False | True |\n",
    "\t  \n",
    "\n",
    "\n",
    "\n",
    "## 优化器相关参数\n",
    "\n",
    "\n",
    "| 参数名字 | 具体含义 | 默认值 | 可选值 |\n",
    "| :--------: | :--------: | :--------: | :---------: |\n",
    "|  name   | 优化器方法名 | \"Momentum\" | \"Momentum\" |\n",
    "| momentum | momentum值 | 0.9| float |\n",
    "| lr.name | 学习率下降方式 | \"Cosine\" | \"Linear\"、\"Piecewise\"等其他下降方式 |\n",
    "| lr.learning_rate | 学习率初始值\t| 0.1 | float |\n",
    "| lr.warmup_epoch | warmup轮数 | 0 | int，如5 |\n",
    "| regularizer.name | 正则化方法名\t| \"L2\" | [\"L1\", \"L2\"] |\n",
    "| regularizer.coeff\t| 正则化系数 | 0.00007 | float|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 生成ImageNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## [3] 数据集划分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10-28 20:25:50 MainThread @logger.py:242] Argv: /opt/conda/envs/python35-paddle120-env/bin/paddlex --split_dataset --format ImageNet --dataset_dir data/data10954/ImageNetDataset --val_value 0.085 --test_value 0\n",
      "[10-28 20:25:50 MainThread @utils.py:79] WRN paddlepaddle version: 2.1.2. The dynamic graph version of PARL is under development, not fully tested and supported\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/parl/remote/communication.py:38: DeprecationWarning: 'pyarrow.default_serialization_context' is deprecated as of 2.0.0 and will be removed in a future version. Use pickle or the pyarrow IPC functionality instead.\n",
      "  context = pyarrow.default_serialization_context()\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/pyarrow/pandas_compat.py:1027: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  'floating': np.float,\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/__init__.py:107: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import MutableMapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/rcsetup.py:20: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Iterable, Mapping\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/matplotlib/colors.py:53: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Sized\n",
      "/opt/conda/envs/python35-paddle120-env/lib/python3.7/site-packages/paddle/tensor/creation.py:125: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  if data.dtype == np.object:\n",
      "2022-10-28 20:25:52 [INFO]\tDataset split starts...\n",
      "2022-10-28 20:25:52 [INFO]\tDataset split done.\n",
      "2022-10-28 20:25:52 [INFO]\tTrain samples: 1980\n",
      "2022-10-28 20:25:52 [INFO]\tEval samples: 180\n",
      "2022-10-28 20:25:52 [INFO]\tTest samples: 0\n",
      "2022-10-28 20:25:52 [INFO]\tSplit files saved in data/data10954/ImageNetDataset\n"
     ]
    }
   ],
   "source": [
    "!paddlex --split_dataset --format ImageNet\\\r\n",
    "    --dataset_dir data/data10954/ImageNetDataset\\\r\n",
    "    --val_value 0.085\\\r\n",
    "    --test_value 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## [4] 定义数据增强、装载数据集"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "在对数据集进行数据增强之前，我们首先需要根据本数据集计算相关参数：  \n",
    "**T.Normalize()：**  \n",
    "初始参数：  \n",
    "**T.Normalize(mean = [0.485, 0.456, 0.406], std = [0.229, 0.224, 0.225])**  \n",
    "为在ImageNet上几百万张图片上的均值和方差，我们需计算本数据集上的均值和方差，并用此数据进行标准化。  \n",
    "```python\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import transforms\n",
    "from dataset.CatDataset import CatDataset\n",
    "\n",
    "trans = transforms.Compose([\n",
    "    transforms.Resize((410, 410)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = CatDataset(\"E:/project/data10954\", \"train_list.txt\", trans)\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "\n",
    "def get_mean_std(loader):\n",
    "    # Var[x] = E[X**2]-E[X]**2\n",
    "    channels_sum, channels_squared_sum, num_batches = 0, 0, 0\n",
    "    for data, _ in loader:\n",
    "        channels_sum += torch.mean(data, dim=[0, 2, 3])\n",
    "        channels_squared_sum += torch.mean(data ** 2, dim=[0, 2, 3])\n",
    "        num_batches += 1\n",
    "\n",
    "    print(num_batches)\n",
    "    print(channels_sum)\n",
    "    mean = channels_sum / num_batches\n",
    "    std = (channels_squared_sum / num_batches - mean ** 2) ** 0.5\n",
    "\n",
    "    return mean, std\n",
    "\n",
    "\n",
    "mean, std = get_mean_std(train_loader)\n",
    "\n",
    "print(mean)\n",
    "print(std)\n",
    "\n",
    "```\n",
    "相关代码如上，经计算，本数据集的相关参数：  \n",
    "**mean = [0.4848, 0.4435, 0.4023],   \n",
    "std = [0.2744, 0.2688, 0.2757]**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# 训练集增强\r\n",
    "train_transforms = T.Compose([\r\n",
    "    T.MixupImage(\r\n",
    "        alpha=1.5,\r\n",
    "        beta=1.5,\r\n",
    "        mixup_epoch=int(300 * 25. / 27)),\r\n",
    "    T.Resize(\r\n",
    "        target_size=438,\r\n",
    "        interp='CUBIC'),\r\n",
    "    # 以图像中心点扩散裁剪长宽为目标尺寸的正方形\r\n",
    "    T.RandomCrop(360),\r\n",
    "    # 以一定的概率对图像进行随机水平翻转\r\n",
    "    T.RandomHorizontalFlip(0.5),\r\n",
    "    # 以一定的概率对图像进行随机像素内容变换，可包括亮度、对比度、饱和度、色相角度、通道顺序的调整，模型训练时的数据增强操作\r\n",
    "    T.RandomDistort(\r\n",
    "        brightness_range=0.25,\r\n",
    "        brightness_prob=0.5,\r\n",
    "        contrast_range=0.25,\r\n",
    "        contrast_prob=0.5,\r\n",
    "        saturation_range=0.25,\r\n",
    "        saturation_prob=0.5,\r\n",
    "        hue_range=18.0,\r\n",
    "        hue_prob=0.5),\r\n",
    "    # 以一定的概率对图像进行高斯模糊\r\n",
    "    T.RandomBlur(0.1),\r\n",
    "    # 对图像进行标准化\r\n",
    "    T.Normalize([0.4848, 0.4435, 0.4023], [0.2744, 0.2688, 0.2757])\r\n",
    "])\r\n",
    "# 验证集增强\r\n",
    "eval_transforms = T.Compose([\r\n",
    "    T.Resize(\r\n",
    "        target_size=410,\r\n",
    "        interp='AREA'),\r\n",
    "    T.CenterCrop(360),\r\n",
    "    T.Normalize([0.4848, 0.4435, 0.4023], [0.2744, 0.2688, 0.2757])\r\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 装载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-28 20:26:11 [INFO]\tStarting to read file list from dataset...\n",
      "2022-10-28 20:26:11 [INFO]\t1980 samples in file data/data10954/ImageNetDataset/train_list.txt\n",
      "2022-10-28 20:26:11 [INFO]\tStarting to read file list from dataset...\n",
      "2022-10-28 20:26:11 [INFO]\t180 samples in file data/data10954/ImageNetDataset/val_list.txt\n"
     ]
    }
   ],
   "source": [
    "train_dataset = pdx.datasets.ImageNet(\r\n",
    "    data_dir='data/data10954/ImageNetDataset',\r\n",
    "    file_list='data/data10954/ImageNetDataset/train_list.txt',\r\n",
    "    label_list='data/data10954/ImageNetDataset/labels.txt',\r\n",
    "    transforms=train_transforms,\r\n",
    "    shuffle=True) # 是否需要对数据集中样本打乱顺序\r\n",
    "\r\n",
    "eval_dataset = pdx.datasets.ImageNet(\r\n",
    "    data_dir='data/data10954/ImageNetDataset',\r\n",
    "    file_list='data/data10954/ImageNetDataset/val_list.txt',\r\n",
    "    label_list='data/data10954/ImageNetDataset/labels.txt',\r\n",
    "    transforms=eval_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 配置 ResNet 模型并训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11']\n"
     ]
    }
   ],
   "source": [
    "print(train_dataset.labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1027 15:12:05.698530    98 device_context.cc:404] Please NOTE: device: 0, GPU Compute Capability: 8.0, Driver API Version: 11.2, Runtime API Version: 11.2\n",
      "W1027 15:12:05.701606    98 device_context.cc:422] device: 0, cuDNN Version: 8.2.\n"
     ]
    }
   ],
   "source": [
    "#初始化模型\r\n",
    "model = pdx.cls.ResNet101_vd_ssld(\r\n",
    "    num_classes=len(train_dataset.labels)\r\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-27 15:12:07 [INFO]\tLoading pretrained model from output/ResNet101_vd_ssld/pretrain/ResNet101_vd_ssld_pretrained.pdparams\n",
      "2022-10-27 15:12:09 [WARNING]\t[SKIP] Shape of pretrained params fc.weight doesn't match.(Pretrained: (2048, 1000), Actual: [2048, 12])\n",
      "2022-10-27 15:12:09 [WARNING]\t[SKIP] Shape of pretrained params fc.bias doesn't match.(Pretrained: (1000,), Actual: [12])\n",
      "2022-10-27 15:12:09 [INFO]\tThere are 530/532 variables loaded into ResNet101_vd_ssld.\n",
      "2022-10-27 15:12:33 [INFO]\t[TRAIN] Epoch 1 finished, loss=2.428278, acc1=0.14687501, acc5=0.5494792 .\n",
      "2022-10-27 15:12:56 [INFO]\t[TRAIN] Epoch 2 finished, loss=1.4307181, acc1=0.6453125, acc5=0.95416665 .\n",
      "2022-10-27 15:12:56 [INFO]\tStart to evaluate(total_samples=180, total_steps=3)...\n",
      "2022-10-27 15:12:58 [INFO]\t[EVAL] Finished, Epoch=2, acc1=0.900000, acc5=0.995833 .\n",
      "2022-10-27 15:12:59 [INFO]\tModel saved in output/ResNet101_vd_ssld/best_model.\n",
      "2022-10-27 15:12:59 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_2, acc1=0.9000000357627869\n",
      "2022-10-27 15:13:00 [INFO]\tModel saved in output/ResNet101_vd_ssld/epoch_2.\n",
      "2022-10-27 15:13:22 [INFO]\t[TRAIN] Epoch 3 finished, loss=0.57823354, acc1=0.8031251, acc5=0.98593754 .\n",
      "2022-10-27 15:13:46 [INFO]\t[TRAIN] Epoch 4 finished, loss=0.46494603, acc1=0.8458333, acc5=0.98854166 .\n",
      "2022-10-27 15:13:46 [INFO]\tStart to evaluate(total_samples=180, total_steps=3)...\n",
      "2022-10-27 15:13:48 [INFO]\t[EVAL] Finished, Epoch=4, acc1=0.908333, acc5=0.991667 .\n",
      "2022-10-27 15:13:49 [INFO]\tModel saved in output/ResNet101_vd_ssld/best_model.\n",
      "2022-10-27 15:13:49 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_4, acc1=0.9083333015441895\n",
      "2022-10-27 15:13:50 [INFO]\tModel saved in output/ResNet101_vd_ssld/epoch_4.\n",
      "2022-10-27 15:14:13 [INFO]\t[TRAIN] Epoch 5 finished, loss=0.47114065, acc1=0.8333333, acc5=0.99062496 .\n",
      "2022-10-27 15:14:35 [INFO]\t[TRAIN] Epoch 6 finished, loss=0.41161117, acc1=0.8541667, acc5=0.9895833 .\n",
      "2022-10-27 15:14:35 [INFO]\tStart to evaluate(total_samples=180, total_steps=3)...\n",
      "2022-10-27 15:14:37 [INFO]\t[EVAL] Finished, Epoch=6, acc1=0.912500, acc5=0.991667 .\n",
      "2022-10-27 15:14:38 [INFO]\tModel saved in output/ResNet101_vd_ssld/best_model.\n",
      "2022-10-27 15:14:38 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_6, acc1=0.9124999642372131\n",
      "2022-10-27 15:14:39 [INFO]\tModel saved in output/ResNet101_vd_ssld/epoch_6.\n",
      "2022-10-27 15:15:02 [INFO]\t[TRAIN] Epoch=7/420, Step=24/24, loss=0.711141, acc1=0.800000, acc5=0.950000, lr=0.025000, time_each_step=0.95s, eta=2:48:22\n",
      "2022-10-27 15:15:02 [INFO]\t[TRAIN] Epoch 7 finished, loss=0.4159809, acc1=0.85208327, acc5=0.98489577 .\n",
      "2022-10-27 15:15:25 [INFO]\t[TRAIN] Epoch 8 finished, loss=0.3877999, acc1=0.8645833, acc5=0.9864583 .\n",
      "2022-10-27 15:15:25 [INFO]\tStart to evaluate(total_samples=180, total_steps=3)...\n",
      "2022-10-27 15:15:27 [INFO]\t[EVAL] Finished, Epoch=8, acc1=0.925000, acc5=1.000000 .\n",
      "2022-10-27 15:15:28 [INFO]\tModel saved in output/ResNet101_vd_ssld/best_model.\n",
      "2022-10-27 15:15:28 [INFO]\tCurrent evaluated best model on eval_dataset is epoch_8, acc1=0.925000011920929\n",
      "2022-10-27 15:15:29 [INFO]\tModel saved in output/ResNet101_vd_ssld/epoch_8.\n",
      "2022-10-27 15:15:53 [INFO]\t[TRAIN] Epoch 9 finished, loss=0.4262445, acc1=0.8536458, acc5=0.98854166 .\n"
     ]
    }
   ],
   "source": [
    "model.train(\r\n",
    "    train_dataset=train_dataset,\r\n",
    "    eval_dataset=eval_dataset,\r\n",
    "    num_epochs=420, #训练轮数\r\n",
    "    train_batch_size=80, #一个step所用到的样本量\r\n",
    "    warmup_steps=(len(train_dataset.file_list) // 80) * 6, #学习率从0经过steps轮迭代增长到设定的学习率\r\n",
    "    learning_rate=0.025, # 学习率\r\n",
    "    lr_decay_epochs=[40, 65, 115, 160, 205], #表示学习率在第几个epoch时衰减一次\r\n",
    "    lr_decay_gamma=0.1, # 学习率衰减率\r\n",
    "\r\n",
    "    save_interval_epochs=2, # 每几轮保存一次\r\n",
    "    log_interval_steps=(len(train_dataset.file_list) // 80) * 7, # 训练日志输出间隔\r\n",
    "\r\n",
    "    pretrain_weights='IMAGENET',\r\n",
    "    #pretrain_weights (str or None): 若指定为'.pdparams'文件时，则从文件加载模型权重；\r\n",
    "    #若为字符串'IMAGENET'，则自动下载在ImageNet图片数据上预训练的模型权重；\r\n",
    "    #若为None，则不使用预训练模型。默认为'IMAGENET'\r\n",
    "    save_dir='output/ResNet101_vd_ssld',\r\n",
    "    use_vdl=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 训练技巧与参数选择\n",
    "### 调优策略\n",
    "在训练网络的过程中，通常会打印每一个epoch的训练集准确率和验证集准确率，二者刻画了该模型在两个数据集上的表现。通常来说，训练集的准确率比验证集准确率微高或者二者相当是比较不错的状态。如果发现训练集的准确率比验证集高很多，说明在这个任务上已经过拟合，需要在训练过程中加入更多的正则，如增大l2_decay的值，加入更多的数据增广策略，加入label_smoothing策略等；如果发现训练集的准确率比验证集低一些，说明在这个任务上可能欠拟合，需要在训练过程中减弱正则效果，如减小l2_decay的值，减少数据增广方式，增大图片crop区域面积，减弱图片拉伸变换，去除label_smoothing等。\n",
    "\n",
    "### 优化器&学习率选择\n",
    "**学习率下降策略：**\n",
    "在整个训练过程中，我们不能使用同样的学习率来更新权重，否则无法到达最优点，所以需要在训练过程中调整学习率的大小。在训练初始阶段，由于权重处于随机初始化的状态，损失函数相对容易进行梯度下降，所以可以设置一个较大的学习率。在训练后期，由于权重参数已经接近最优值，较大的学习率无法进一步寻找最优值，所以需要设置一个较小的学习率。  \n",
    "Cosine_decay和piecewise_decay的学习率变化曲线如下图所示，容易观察到，在整个训练过程中，cosine_decay都保持着较大的学习率，所以其收敛较为缓慢，但是最终的收敛效果较peicewise_decay更好一些。\n",
    "![](https://ai-studio-static-online.cdn.bcebos.com/84eec8a5a72a4a10a453a3228bea612ab0bb647fb80e417bbf7c77c155ac2c1c)\n",
    "\n",
    "\n",
    "\n",
    "**warmup策略：**\n",
    "让学习率先进行预热，在训练初期，本文不直接使用最大的学习率，而是用一个逐渐增大的学习率去训练网络，当学习率增大到最高点时，再使用学习率下降策略中提到的学习率下降方式衰减学习率的值。  \n",
    "\n",
    "```\n",
    "Optimizer:\n",
    "  name: AdamW\n",
    "  beta1: 0.9\n",
    "  beta2: 0.999\n",
    "  epsilon: 1e-8\n",
    "  weight_decay: 0.05\n",
    "  no_weight_decay_name: absolute_pos_embed relative_position_bias_table .bias norm \n",
    "  one_dim_param_no_weight_decay: True\n",
    "  lr:\n",
    "    name: Cosine\n",
    "    learning_rate: 3e-6\n",
    "    eta_min: 1e-6\n",
    "    warmup_epoch: 20\n",
    "    warmup_start_lr: 1e-6\n",
    "```\n",
    "\n",
    "### batch_size\n",
    "batch_size决定了一次将多少数据送入神经网络参与训练，当batch_size的值与学习率的值呈线性关系时，收敛精度几乎不受影响。因本文采用飞桨—至尊版GPU环境，所以在条件的允许下，尽量增大batch_size值的大小  \n",
    "（从64开始尝试，若训练过程中出现内存溢出错误，则减小batch_size值的大小。）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 模型预测，另存为提交文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = pdx.load_model('output/ResNet101_vd_ssld/epoch_40') # 加载模型\r\n",
    "model.get_model_info() # 显示信息"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## 生成 work/result.csv \n",
    "通过csv文件去查看分类结果，分类结果并不是100%正确，在有经过数据增强和神经网络的学习前，正确率大约在20%，经过数据增强和残差神经网络学习以后可以到达90%左右，但是这其中也不排除训练次数太多导致的过拟合，最终使正确率降低了一些。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import glob\r\n",
    "\r\n",
    "test_list = glob.glob('data/data10954/cat_12_test/*.jpg')\r\n",
    "test_df = pd.DataFrame() # 创建表结构\r\n",
    "\r\n",
    "for i in range(len(test_list)):\r\n",
    "    img = Image.open(test_list[i]).convert('RGB')\r\n",
    "    img = np.asarray(img, dtype='float32') # 转换数据类型\r\n",
    "\r\n",
    "    result = model.predict(img[:, :, [2, 1, 0]]) # 预测结果\r\n",
    "    test_df.at[i, 'name'] = str(test_list[i]).split('/')[-1] # 文件名\r\n",
    "    test_df.at[i, 'cls'] = int(result[0]['category_id']) # 类别\r\n",
    "\r\n",
    "test_df[['name']] = test_df[['name']].astype(str)\r\n",
    "test_df[['cls']] = test_df[['cls']].astype(int)\r\n",
    "test_df.to_csv('work/result.csv', index=False, header=False) # 生成csv文件\r\n",
    "\r\n",
    "test_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "py35-paddle1.2.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
